{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b61cda3a-fd9a-4d66-9174-45bddee9d9e6",
   "metadata": {},
   "source": [
    "# Taxi Tip Prediction using Scikit-Learn and Snap ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2fe800-8921-4142-95b5-4140c2367cc2",
   "metadata": {},
   "source": [
    "### In this exercise session you will consolidate your machine learning (ML) modeling skills by using a popular regression model: Decision Tree. You will use a real dataset to train such a model. The dataset includes information about taxi tip and was collected and provided to the NYC Taxi and Limousine Commission (TLC) by technology providers authorized under the Taxicab & Livery Passenger Enhancement Programs (TPEP/LPEP). You will use the trained model to predict the amount of tip paid.\n",
    "\n",
    "### In the current exercise session, you will practice not only the Scikit-Learn Python interface, but also the Python API offered by the Snap Machine Learning (Snap ML) library. Snap ML is a high-performance IBM library for ML modeling. It provides highly-efficient CPU/GPU implementations of linear models and tree-based models. Snap ML not only accelerates ML algorithms through system awareness, but it also offers novel ML algorithms with best-in-class accuracy. For more information, please visit https://www.zurich.ibm.com/snapml/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14377df-966b-4878-b387-c72c616e43ea",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "## Perform basic data preprocessing using Scikit-Learn\n",
    "## Model a regression task using the Scikit-Learn and Snap ML Python APIs\n",
    "## Train a Decision Tree Regressor model using Scikit-Learn and Snap ML\n",
    "## Run inference and assess the quality of the trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068466b3-00ec-4d06-a507-93950c7159fc",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### The dataset used in this exercise session is publicly available here: https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page (all rights reserved by Taxi & Limousine Commission(TLC), City of New York). The TLC Yellow Taxi Trip Records of June, 2019 are used in this notebook. The prediction of the tip amount can be modeled as a regression problem. To train the model you can use part of the input dataset and the remaining data can be used to assess the quality of the trained model. First, let's download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45311005-cd29-4142-bd06-73a586577b10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-12 16:00:29--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%203/data/yellow_tripdata_2019-06.csv\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104, 169.63.118.104\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 364904448 (348M) [text/csv]\n",
      "Saving to: ‘yellow_tripdata_2019-06.csv’\n",
      "\n",
      "yellow_tripdata_201 100%[===================>] 348.00M  42.3MB/s    in 9.6s    \n",
      "\n",
      "2024-11-12 16:00:41 (36.2 MB/s) - ‘yellow_tripdata_2019-06.csv’ saved [364904448/364904448]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download June 2020 TLC Yellow Taxi Trip records\n",
    "!wget -nc https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%203/data/yellow_tripdata_2019-06.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6979ebaa-7c5d-4c96-8e25-07053a10746a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# download June 2020 TLC Yellow Taxi Trip records\n",
    "# Uncomment the next line, if working locally\n",
    "#!curl https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%203/data/yellow_tripdata_2019-06.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84098a34-2328-488f-a924-cbe36ed40cb7",
   "metadata": {},
   "source": [
    "## Did you know? When it comes to Machine Learning, you will most likely be working with large datasets. As a business, where can you host your data? IBM is offering a unique opportunity for businesses, with 10 Tb of IBM Cloud Object Storage: Sign up now for free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eeac958-103f-4461-900d-a76b3c831c98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snapml==1.8.2\n",
      "  Downloading snapml-1.8.2-cp37-cp37m-manylinux2010_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from snapml==1.8.2) (1.21.6)\n",
      "Requirement already satisfied: scikit-learn in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from snapml==1.8.2) (0.20.1)\n",
      "Requirement already satisfied: scipy in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from snapml==1.8.2) (1.7.3)\n",
      "Installing collected packages: snapml\n",
      "Successfully installed snapml-1.8.2\n"
     ]
    }
   ],
   "source": [
    "# Snap ML is available on PyPI. To install it simply run the pip command below.\n",
    "!pip install snapml==1.8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b3fec7e-0b3a-45c4-ae99-c7e9fb0a320b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    }
   ],
   "source": [
    "# Import the libraries we need to use in this lab\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize, StandardScaler, MinMaxScaler\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "import warnings\n",
    "import gc, sys\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96012754-f245-451e-950c-1818a44cea48",
   "metadata": {},
   "source": [
    "## Dataset Analysis\n",
    "### In this section you will read the dataset in a Pandas dataframe and visualize its content. You will also look at some data statistics.\n",
    "\n",
    "### Note: A Pandas dataframe is a two-dimensional, size-mutable, potentially heterogeneous tabular data structure. For more information: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "413ab623-4f15-4c87-b421-36a6fd03fef5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3936004 observations in the dataset.\n",
      "There are 18 variables in the dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-06-01 00:55:13</td>\n",
       "      <td>2019-06-01 00:56:17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>145.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-06-01 00:06:31</td>\n",
       "      <td>2019-06-01 00:06:52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>262.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.30</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-06-01 00:17:05</td>\n",
       "      <td>2019-06-01 00:36:38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>74.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>18.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-06-01 00:59:02</td>\n",
       "      <td>2019-06-01 00:59:12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>145.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-06-01 00:03:25</td>\n",
       "      <td>2019-06-01 00:15:42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>113.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.95</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2019-06-01 00:55:13   2019-06-01 00:56:17              1.0   \n",
       "1         1  2019-06-01 00:06:31   2019-06-01 00:06:52              1.0   \n",
       "2         1  2019-06-01 00:17:05   2019-06-01 00:36:38              1.0   \n",
       "3         1  2019-06-01 00:59:02   2019-06-01 00:59:12              0.0   \n",
       "4         1  2019-06-01 00:03:25   2019-06-01 00:15:42              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0            0.0         1.0                  N         145.0         145.0   \n",
       "1            0.0         1.0                  N         262.0         263.0   \n",
       "2            4.4         1.0                  N          74.0           7.0   \n",
       "3            0.8         1.0                  N         145.0         145.0   \n",
       "4            1.7         1.0                  N         113.0         148.0   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0           2.0          3.0    0.5      0.5        0.00           0.0   \n",
       "1           2.0          2.5    3.0      0.5        0.00           0.0   \n",
       "2           2.0         17.5    0.5      0.5        0.00           0.0   \n",
       "3           2.0          2.5    1.0      0.5        0.00           0.0   \n",
       "4           1.0          9.5    3.0      0.5        2.65           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  \n",
       "0                    0.3          4.30                   0.0  \n",
       "1                    0.3          6.30                   2.5  \n",
       "2                    0.3         18.80                   0.0  \n",
       "3                    0.3          4.30                   0.0  \n",
       "4                    0.3         15.95                   2.5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the input data\n",
    "raw_data = pd.read_csv('yellow_tripdata_2019-06.csv')\n",
    "print(\"There are \" + str(len(raw_data)) + \" observations in the dataset.\")\n",
    "print(\"There are \" + str(len(raw_data.columns)) + \" variables in the dataset.\")\n",
    "\n",
    "# display first rows in the dataset\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d72339b-d082-4ee8-bdad-bd88850bb155",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3935999</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-06-17 23:27:54</td>\n",
       "      <td>2019-06-17 23:37:37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>75.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.3</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3936000</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-06-17 23:41:25</td>\n",
       "      <td>2019-06-17 23:48:50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>161.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.8</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3936001</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-06-17 23:47:39</td>\n",
       "      <td>2019-06-17 23:54:02</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>211.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.3</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3936002</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-06-17 23:55:44</td>\n",
       "      <td>2019-06-18 00:06:50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>164.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.3</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3936003</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "3935999         2  2019-06-17 23:27:54   2019-06-17 23:37:37              1.0   \n",
       "3936000         2  2019-06-17 23:41:25   2019-06-17 23:48:50              1.0   \n",
       "3936001         2  2019-06-17 23:47:39   2019-06-17 23:54:02              5.0   \n",
       "3936002         2  2019-06-17 23:55:44   2019-06-18 00:06:50              5.0   \n",
       "3936003         2                  NaN                   NaN              NaN   \n",
       "\n",
       "         trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
       "3935999           3.36         1.0                  N          75.0   \n",
       "3936000           1.64         1.0                  N         161.0   \n",
       "3936001           2.00         1.0                  N         211.0   \n",
       "3936002           3.06         1.0                  N         164.0   \n",
       "3936003            NaN         NaN                NaN           NaN   \n",
       "\n",
       "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "3935999         161.0           1.0         11.5    0.5      0.5         0.0   \n",
       "3936000         234.0           1.0          8.0    0.5      0.5         4.0   \n",
       "3936001         186.0           2.0          7.5    0.5      0.5         0.0   \n",
       "3936002         236.0           2.0         11.5    0.5      0.5         0.0   \n",
       "3936003           NaN           NaN          NaN    NaN      NaN         NaN   \n",
       "\n",
       "         tolls_amount  improvement_surcharge  total_amount  \\\n",
       "3935999           0.0                    0.3          15.3   \n",
       "3936000           0.0                    0.3          15.8   \n",
       "3936001           0.0                    0.3          11.3   \n",
       "3936002           0.0                    0.3          15.3   \n",
       "3936003           NaN                    NaN           NaN   \n",
       "\n",
       "         congestion_surcharge  \n",
       "3935999                   2.5  \n",
       "3936000                   2.5  \n",
       "3936001                   2.5  \n",
       "3936002                   2.5  \n",
       "3936003                   NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726f3a41-a6b9-4b73-91aa-13ca164059ef",
   "metadata": {},
   "source": [
    "## Each row in the dataset represents a taxi trip. As shown above, each row has 18 variables. One variable is called tip_amount and represents the target variable. Your objective will be to train a model that uses the other variables to predict the value of the tip_amount variable. Let's first clean the dataset and retrieve basic statistics about the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0c2a46-4944-434b-bdb1-593ca43b0c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some trips report 0 tip. it is assumed that these tips were paid in cash.\n",
    "# for this study we drop all these rows\n",
    "raw_data = raw_data[raw_data['tip_amount'] > 0]\n",
    "\n",
    "# we also remove some outliers, namely those where the tip was larger than the fare cost\n",
    "raw_data = raw_data[(raw_data['tip_amount'] <= raw_data['fare_amount'])]\n",
    "\n",
    "# we remove trips with very large fare cost\n",
    "raw_data = raw_data[((raw_data['fare_amount'] >=2) & (raw_data['fare_amount'] < 200))]\n",
    "\n",
    "# we drop variables that include the target variable in it, namely the total_amount\n",
    "clean_data = raw_data.drop(['total_amount'], axis=1)\n",
    "\n",
    "# release memory occupied by raw_data as we do not need it anymore\n",
    "# we are dealing with a large dataset, thus we need to make sure we do not run out of memory\n",
    "del raw_data\n",
    "gc.collect()\n",
    "\n",
    "# print the number of trips left in the dataset\n",
    "print(\"There are \" + str(len(clean_data)) + \" observations in the dataset.\")\n",
    "print(\"There are \" + str(len(clean_data.columns)) + \" variables in the dataset.\")\n",
    "\n",
    "plt.hist(clean_data.tip_amount.values, 16, histtype='bar', facecolor='g')\n",
    "plt.show()\n",
    "\n",
    "print(\"Minimum amount value is \", np.min(clean_data.tip_amount.values))\n",
    "print(\"Maximum amount value is \", np.max(clean_data.tip_amount.values))\n",
    "print(\"90% of the trips have a tip amount less or equal than \", np.percentile(clean_data.tip_amount.values, 90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e1f741-f650-4095-a1a8-1de8175151f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display first rows in the dataset\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1c1bef-547a-43ef-9b90-b4c1438e7835",
   "metadata": {},
   "source": [
    "## By looking at the dataset in more detail, we see that it contains information such as pick-up and drop-off dates/times, pick-up and drop-off locations, payment types, driver-reported passenger counts etc. Before actually training a ML model, we will need to preprocess the data. We need to transform the data in a format that will be correctly handled by the models. For instance, we need to encode the categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966aa816-59bf-49b2-b296-cb295cb07bfa",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing\n",
    "### In this subsection you will prepare the data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eab912a-ed21-4ea0-9e70-3c6ba4b9546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'tpep_dropoff_datetime' and 'tpep_pickup_datetime' columns to datetime objects\n",
    "clean_data['tpep_dropoff_datetime'] = pd.to_datetime(clean_data['tpep_dropoff_datetime'])\n",
    "clean_data['tpep_pickup_datetime'] = pd.to_datetime(clean_data['tpep_pickup_datetime'])\n",
    "\n",
    "# Extract pickup and dropoff hour\n",
    "clean_data['pickup_hour'] = clean_data['tpep_pickup_datetime'].dt.hour\n",
    "clean_data['dropoff_hour'] = clean_data['tpep_dropoff_datetime'].dt.hour\n",
    "\n",
    "# Extract pickup and dropoff day of the week (0 = Monday, 6 = Sunday)\n",
    "clean_data['pickup_day'] = clean_data['tpep_pickup_datetime'].dt.weekday\n",
    "clean_data['dropoff_day'] = clean_data['tpep_dropoff_datetime'].dt.weekday\n",
    "\n",
    "# Calculate trip time in seconds\n",
    "clean_data['trip_time'] = (clean_data['tpep_dropoff_datetime'] - clean_data['tpep_pickup_datetime']).dt.total_seconds()\n",
    "\n",
    "# Ideally use the full dataset for this exercise.\n",
    "# However, if you run into out-of-memory issues due to the data size, reduce it.\n",
    "# For instance, in this example, we use only the first 200,000 samples.\n",
    "first_n_rows = 200000\n",
    "clean_data = clean_data.head(first_n_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f0b723-669b-4395-bb40-79038a1f5af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the pickup and dropoff datetimes\n",
    "clean_data = clean_data.drop(['tpep_pickup_datetime', 'tpep_dropoff_datetime'], axis=1)\n",
    "\n",
    "# some features are categorical, we need to encode them\n",
    "# to encode them we use one-hot encoding from the Pandas package\n",
    "get_dummy_col = [\"VendorID\",\"RatecodeID\",\"store_and_fwd_flag\",\"PULocationID\", \"DOLocationID\",\"payment_type\", \"pickup_hour\", \"dropoff_hour\", \"pickup_day\", \"dropoff_day\"]\n",
    "proc_data = pd.get_dummies(clean_data, columns = get_dummy_col)\n",
    "\n",
    "# release memory occupied by clean_data as we do not need it anymore\n",
    "# we are dealing with a large dataset, thus we need to make sure we do not run out of memory\n",
    "del clean_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fbd3a3-c1f0-40e3-8516-19991c3f12ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the labels from the dataframe\n",
    "y = proc_data[['tip_amount']].values.astype('float32')\n",
    "\n",
    "# drop the target variable from the feature matrix\n",
    "proc_data = proc_data.drop(['tip_amount'], axis=1)\n",
    "\n",
    "# get the feature matrix used for training\n",
    "X = proc_data.values\n",
    "\n",
    "# normalize the feature matrix\n",
    "X = normalize(X, axis=1, norm='l1', copy=False)\n",
    "\n",
    "# print the shape of the features matrix and the labels vector\n",
    "print('X.shape=', X.shape, 'y.shape=', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8bcee2-4f25-4b6e-ab4d-f28e504a6dd2",
   "metadata": {},
   "source": [
    "## Dataset Train/Test Split\n",
    "### Now that the dataset is ready for building the classification models, you need to first divide the pre-processed dataset into a subset to be used for training the model (the train set) and a subset to be used for evaluating the quality of the model (the test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7266def2-b6ad-43ef-9b0d-723fe817db26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print('X_train.shape=', X_train.shape, 'Y_train.shape=', y_train.shape)\n",
    "print('X_test.shape=', X_test.shape, 'Y_test.shape=', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd4fbf2-19f6-4464-8145-3b4791677c97",
   "metadata": {},
   "source": [
    "## Build a Decision Tree Regressor model with Scikit-Learn¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b70714-91ab-4d5c-9787-ea6120458949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Decision Tree Regression Model from scikit-learn\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# for reproducible output across multiple function calls, set random_state to a given integer value\n",
    "sklearn_dt = DecisionTreeRegressor(max_depth=8, random_state=35)\n",
    "\n",
    "# train a Decision Tree Regressor using scikit-learn\n",
    "t0 = time.time()\n",
    "sklearn_dt.fit(X_train, y_train)\n",
    "sklearn_time = time.time()-t0\n",
    "print(\"[Scikit-Learn] Training time (s):  {0:.5f}\".format(sklearn_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec59be4-02d3-4e08-ad9e-2a9553711310",
   "metadata": {},
   "source": [
    "## Build a Decision Tree Regressor model with Snap ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487c6ad7-f9d6-401b-a0e7-1cda35969ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Decision Tree Regressor Model from Snap ML\n",
    "from snapml import DecisionTreeRegressor\n",
    "\n",
    "# in contrast to sklearn's Decision Tree, Snap ML offers multi-threaded CPU/GPU training \n",
    "# to use the GPU, one needs to set the use_gpu parameter to True\n",
    "# snapml_dt = DecisionTreeRegressor(max_depth=4, random_state=45, use_gpu=True)\n",
    "\n",
    "# to set the number of CPU threads used at training time, one needs to set the n_jobs parameter\n",
    "# for reproducible output across multiple function calls, set random_state to a given integer value\n",
    "snapml_dt = DecisionTreeRegressor(max_depth=8, random_state=45, n_jobs=4)\n",
    "\n",
    "# train a Decision Tree Regressor model using Snap ML\n",
    "t0 = time.time()\n",
    "snapml_dt.fit(X_train, y_train)\n",
    "snapml_time = time.time()-t0\n",
    "print(\"[Snap ML] Training time (s):  {0:.5f}\".format(snapml_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c7d0b3-ab7b-4e35-a127-9b48287e584a",
   "metadata": {},
   "source": [
    "## Evaluate the Scikit-Learn and Snap ML Decision Tree Regressor Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78a8bf8-5584-45f4-a2e6-8c7031ca503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snap ML vs Scikit-Learn training speedup\n",
    "training_speedup = sklearn_time/snapml_time\n",
    "print('[Decision Tree Regressor] Snap ML vs. Scikit-Learn speedup : {0:.2f}x '.format(training_speedup))\n",
    "\n",
    "# run inference using the sklearn model\n",
    "sklearn_pred = sklearn_dt.predict(X_test)\n",
    "\n",
    "# evaluate mean squared error on the test dataset\n",
    "sklearn_mse = mean_squared_error(y_test, sklearn_pred)\n",
    "print('[Scikit-Learn] MSE score : {0:.3f}'.format(sklearn_mse))\n",
    "\n",
    "# run inference using the Snap ML model\n",
    "snapml_pred = snapml_dt.predict(X_test)\n",
    "\n",
    "# evaluate mean squared error on the test dataset\n",
    "snapml_mse = mean_squared_error(y_test, snapml_pred)\n",
    "print('[Snap ML] MSE score : {0:.3f}'.format(snapml_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1444ed1e-e399-4a8b-bf4d-5a8a64f60a6b",
   "metadata": {},
   "source": [
    "## As shown above both decision tree models provide the same score on the test dataset. However Snap ML runs the training routine faster than Scikit-Learn. This is one of the advantages of using Snap ML: acceleration of training of classical machine learning models, such as linear and tree-based models. For more Snap ML examples, please visit https://github.com/IBM/snapml-examples. Moreover, as shown above, not only is Snap ML seemlessly accelerating scikit-learn applications, but the library's Python API is also compatible with scikit-learn metrics and data preprocessors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700b51a9-ebe8-4356-9b49-55a82e3d0074",
   "metadata": {},
   "source": [
    "## Practice\n",
    "### Lets train a SnapML Decision Tree Regressor with the max_depth parameter set to 12, random_state set to 45, and n_jobs set to 4 and compare its Mean Squared Error to the decision tree regressor we trained previously\n",
    "\n",
    "### Start by creating and training the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f1c361-01d7-4739-9bc8-52ffd683ab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor(max_depth=12, random_state=45, n_jobs=4)\n",
    "\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b0ee56-5892-4a81-9c1f-facd16cfd3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tree.predict(X_test)\n",
    "\n",
    "print(\"MSE: \", mean_squared_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44c0c17-202a-4664-b91d-f8225bf047a7",
   "metadata": {},
   "source": [
    "## We learned that increasing the max_depth parameter to 12 increases the MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8463bd4e-2e51-498f-8e96-a8ddbff193e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90594bc-566d-432f-b0f3-25f2601f34cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
